{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b02da6f2585e11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:43:16.255820Z",
     "start_time": "2024-10-18T10:43:14.808531Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.helper_clustering_functions import KMeanClustering ,kmeans_with_smape_ts ,kmeans_with_min_distance\n",
    "from utils.helper_similarity_metrics import calculate_dtw_distance , calculate_error_metrics ,calculate_cosine_similarity_char ,CoinCrossMappingSimilarity ,smape,smape_distance_metric\n",
    "from utils.helper_visualization_functions import plot_and_save , cluster_visualization_of_time_series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521cfe51-87a1-4165-9b49-30b9051bfbf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:43:16.275441Z",
     "start_time": "2024-10-18T10:43:16.268895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Directories : ProcessedData\n",
      "Creating Directories : VisualizationData\n",
      "Creating Directories : TestingGarbage\n",
      "Creating Directories : SimilarityResults\n",
      "Creating Directories : ClusterResultsVisualization\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "directory_names = {\n",
    "    \"preprocessed_data_dir_name\":\"ProcessedData\",\n",
    "    \"visualization_data_dir_name\":\"VisualizationData\",\n",
    "    \"testing_garbage_dir_name\" :\"TestingGarbage\",\n",
    "    \"ResultsDirectory\":\"SimilarityResults\",\n",
    "    \"cluster_dir_path\":\"ClusterResultsVisualization\"\n",
    "}\n",
    "for key , value in directory_names.items():\n",
    "    print(f\"Creating Directories : {value}\")\n",
    "    os.makedirs(directory_names[key], exist_ok=True)\n",
    "    \n",
    "files_path = {\n",
    "    'raw_price_data' : os.path.join(\"Datasets\",\"raw_datasets\",\"prices.csv\"),\n",
    "    'raw_token_names' : os.path.join(\"Datasets\",\"raw_datasets\",\"token_names.csv\"),\n",
    "    \"token_names\":os.path.join(\"TestingGarbage\",\"token_names.csv\"),\n",
    "    \"similarity_results_file_path\":os.path.join(\"SimilarityResults\",\"similarity_results_version_0.1.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ae2aa-ba8f-4276-9f56-f5fdd70b4934",
   "metadata": {},
   "source": [
    "# Helping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08c61cd-ad58-4c73-a916-146efb50ae7f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of price data : (22021830, 4)\n",
      "shap of token names data : (55787, 4)\n",
      "Number of Unique Token : 55787\n",
      "Number of Unique Token after merging : 16369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10191/1641379046.py:35: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  price_pivot = price_pivot.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # step-1 Reading price data \n",
    "    cols_to_ignore = ['Unnamed: 0']\n",
    "    raw_price_df = pd.read_csv(\n",
    "                        files_path['raw_price_data'],\n",
    "                        compression='gzip',\n",
    "                        usecols=lambda col: col not in cols_to_ignore)\n",
    "    \n",
    "    # raw_price_df =  raw_price_df.head(1000*20)\n",
    "    # step-2 Reading Token data\n",
    "    token_names_df = pd.read_csv(files_path['raw_token_names'] )\n",
    "\n",
    "    # token_names_df = token_names_df.head(1000)\n",
    "    number_of_unique_token =  len(token_names_df['id'].unique())\n",
    "    \n",
    "    print(f\"Shape of price data : {raw_price_df.shape}\")\n",
    "    print(f\"shap of token names data : {token_names_df.shape}\")\n",
    "    print(f\"Number of Unique Token : {number_of_unique_token}\")\n",
    "\n",
    "    # step-3 Merging the data\n",
    "    merged_df = raw_price_df.merge(token_names_df, left_on=['network_id', 'base_currency'], right_on=['network_id', 'id'])\n",
    "    # merged_df = raw_price_df.merge(token_names_df, left_on=['base_currency'], right_on=['id'])\n",
    "    \n",
    "    number_of_unique_token_after_merging =  len(merged_df['base_currency'].unique())\n",
    "    print(f\"Number of Unique Token after merging : {number_of_unique_token_after_merging}\")\n",
    "\n",
    "    merged_df['token_id'] = merged_df['base_currency'].astype(str) + '_' + merged_df['network_id'].astype(str)\n",
    "\n",
    "    selective_base_currency = list(merged_df['base_currency'].unique())[:-1]\n",
    "\n",
    "    merged_df = merged_df[ merged_df['base_currency'].isin(selective_base_currency)  ]\n",
    "\n",
    "    price_pivot = merged_df.pivot_table(index='timestamp_utc', columns='token_id', values='open')\n",
    "    price_pivot = price_pivot.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    price_scaled = scaler.fit_transform(price_pivot.T)  # Transpose so each row is a token\n",
    "\n",
    "\n",
    "    # labels = KMeanClustering(n_clusters=10,\n",
    "    #                 price_scaled=price_scaled,\n",
    "    #                metric = \"dtw\",\n",
    "    #                 max_iter=50)\n",
    "    \n",
    "    # cluster_results = pd.DataFrame({'token_id': price_pivot.columns, 'cluster': labels})\n",
    "\n",
    "    # results_with_cluster_id = pd.merge(merged_df_filtered,cluster_results,on='token_id')\n",
    "\n",
    "    # results_with_cluster_id['timestamp_utc'] = pd.to_datetime(results_with_cluster_id['timestamp_utc'])\n",
    "    # results_with_cluster_id = results_with_cluster_id.sort_values(by='timestamp_utc')\n",
    "\n",
    "    # cluster_visualization_of_time_series(results_with_cluster_id=results_with_cluster_id,cluster_dir_path = directory_names['cluster_dir_path'])\n",
    "\n",
    "\n",
    "        \n",
    "    # Perform DBSCAN clustering\n",
    "    \n",
    "    print(\"Clustering .....\")\n",
    "    dbscan = DBSCAN(eps=100, min_samples=3, metric=smape_distance_metric)\n",
    "    \n",
    "    labels = dbscan.fit_predict(price_pivot.T.values)\n",
    "    \n",
    "    cluster_results = pd.DataFrame({'token_id': price_pivot.columns, 'cluster': labels})\n",
    "    \n",
    "    results_with_cluster_id = pd.merge(merged_df,cluster_results,on='token_id')\n",
    "    \n",
    "    results_with_cluster_id['timestamp_utc'] = pd.to_datetime(results_with_cluster_id['timestamp_utc'])\n",
    "    results_with_cluster_id = results_with_cluster_id.sort_values(by='timestamp_utc')\n",
    "    \n",
    "    cluster_visualization_of_time_series(results_with_cluster_id=results_with_cluster_id,cluster_dir_path = directory_names['cluster_dir_path'])\n",
    "    \n",
    "    price_pivot_df = results_with_cluster_id.pivot_table(index='timestamp_utc', columns='token_id', values='open')\n",
    "    \n",
    "    \n",
    "    total_detected_similar_tokens = CoinCrossMappingSimilarity(results_with_cluster_id=results_with_cluster_id, price_pivot_df=price_pivot_df,\n",
    "                                                               files_path = files_path,\n",
    "                                                               directory_names=directory_names)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
